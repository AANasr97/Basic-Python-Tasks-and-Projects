{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the necessary libraries.\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the website to be scraped\n",
    "url = \"https://books.toscrape.com/\"\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "# Get all the book categories from the sidebar\n",
    "categories = soup.find('div', class_='side_categories').find_all('a')\n",
    "category_urls = [url + category['href'] for category in categories[1:]]\n",
    "# Adjust links to solve pagination\n",
    "page_num = 1\n",
    "# category_urls = [link[:-10] + f'page-{page_num}' + link[-5:] for link in category_urls]\n",
    "\n",
    "category_links = []\n",
    "for link in category_urls:\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, \"lxml\")\n",
    "        soup.find('li', {'class':'current'}).text.split('of')[1].strip()\n",
    "        category_links.append(link[:-10] + f'page-{page_num}' + link[-5:])\n",
    "    except:\n",
    "        category_links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel has 1 Pages  Mystery has 2 Pages  Historical Fiction has 2 Pages  Sequential Art has 4 Pages  Classics has 1 Pages  Philosophy has 1 Pages  Romance has 2 Pages  Womens Fiction has 1 Pages  Fiction has 4 Pages  Childrens has 2 Pages  Religion has 1 Pages  Nonfiction has 6 Pages  Music has 1 Pages  Default has 8 Pages  Science Fiction has 1 Pages  Sports and Games has 1 Pages  Add a comment has 4 Pages  Fantasy has 3 Pages  New Adult has 1 Pages  Young Adult has 3 Pages  Science has 1 Pages  Poetry has 1 Pages  Paranormal has 1 Pages  Art has 1 Pages  Psychology has 1 Pages  Autobiography has 1 Pages  Parenting has 1 Pages  Adult Fiction has 1 Pages  Humor has 1 Pages  Horror has 1 Pages  History has 1 Pages  Food and Drink has 2 Pages  Christian Fiction has 1 Pages  Business has 1 Pages  Biography has 1 Pages  Thriller has 1 Pages  Contemporary has 1 Pages  Spirituality has 1 Pages  Academic has 1 Pages  Self Help has 1 Pages  Historical has 1 Pages  Christian has 1 Pages  Suspense has 1 Pages  Short Stories has 1 Pages  Novels has 1 Pages  Health has 1 Pages  Politics has 1 Pages  Cultural has 1 Pages  Erotica has 1 Pages  Crime has 1 Pages  "
     ]
    }
   ],
   "source": [
    "# Loop through each category and scrape the pagination details\n",
    "for category_url in category_links:\n",
    "    response = requests.get(category_url)\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    \n",
    "    # Get the category name\n",
    "    category = soup.find('h1').text.strip()\n",
    "    \n",
    "    try:\n",
    "        total_pages = int(soup.find('li', {'class':'current'}).text.split('of')[1].strip())\n",
    "        print(f'{category} has {total_pages} Pages', end='  ')\n",
    "    except:\n",
    "        total_pages = 1\n",
    "        print(f'{category} has {total_pages} Pages', end='  ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the re.findall(r'\\d+', string) part.\n",
    "This uses the re.findall() function from the re module in Python to find all non-overlapping matches of one or more digits (\\d+) in the given string string. \n",
    "The result is a list of all the digit strings that were found in the original string, in the order that they appear.\n",
    "\n",
    "For example, in the given string \"Travel has 1 Pages Mystery has 2 Pages\", re.findall(r'\\d+', string) would return the list ['1', '2']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# The given string that contains numbers to be summed\n",
    "string = 'Travel has 1 Pages  Mystery has 2 Pages  Historical Fiction has 2 Pages  Sequential Art has 4 Pages  Classics has 1 Pages  Philosophy has 1 Pages  Romance has 2 Pages  Womens Fiction has 1 Pages  Fiction has 4 Pages  Childrens has 2 Pages  Religion has 1 Pages  Nonfiction has 6 Pages  Music has 1 Pages  Default has 8 Pages  Science Fiction has 1 Pages  Sports and Games has 1 Pages  Add a comment has 4 Pages  Fantasy has 3 Pages  New Adult has 1 Pages  Young Adult has 3 Pages  Science has 1 Pages  Poetry has 1 Pages  Paranormal has 1 Pages  Art has 1 Pages  Psychology has 1 Pages  Autobiography has 1 Pages  Parenting has 1 Pages  Adult Fiction has 1 Pages  Humor has 1 Pages  Horror has 1 Pages  History has 1 Pages  Food and Drink has 2 Pages  Christian Fiction has 1 Pages  Business has 1 Pages  Biography has 1 Pages  Thriller has 1 Pages  Contemporary has 1 Pages  Spirituality has 1 Pages  Academic has 1 Pages  Self Help has 1 Pages  Historical has 1 Pages  Christian has 1 Pages  Suspense has 1 Pages  Short Stories has 1 Pages  Novels has 1 Pages  Health has 1 Pages  Politics has 1 Pages  Cultural has 1 Pages  Erotica has 1 Pages  Crime has 1 Pages  '\n",
    "\n",
    "# Use regular expressions to find all non-overlapping matches of one or more digits in the string\n",
    "numbers = re.findall(r'\\d+', string)\n",
    "\n",
    "# Convert the list of digit strings to a list of integers and add them up\n",
    "sum_numbers = sum(map(int, numbers))\n",
    "\n",
    "# Print the total sum of all the numbers in the string\n",
    "print(sum_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Scraping Travel\n",
      "Done Scraping Mystery From 2 Pages\n",
      "Done Scraping Historical Fiction From 2 Pages\n",
      "Done Scraping Sequential Art From 4 Pages\n",
      "Done Scraping Classics\n",
      "Done Scraping Philosophy\n",
      "Done Scraping Romance From 2 Pages\n",
      "Done Scraping Womens Fiction\n",
      "Done Scraping Fiction From 4 Pages\n",
      "Done Scraping Childrens From 2 Pages\n",
      "Done Scraping Religion\n",
      "Done Scraping Nonfiction From 6 Pages\n",
      "Done Scraping Music\n",
      "Done Scraping Default From 8 Pages\n",
      "Done Scraping Science Fiction\n",
      "Done Scraping Sports and Games\n",
      "Done Scraping Add a comment From 4 Pages\n",
      "Done Scraping Fantasy From 3 Pages\n",
      "Done Scraping New Adult\n",
      "Done Scraping Young Adult From 3 Pages\n",
      "Done Scraping Science\n",
      "Done Scraping Poetry\n",
      "Done Scraping Paranormal\n",
      "Done Scraping Art\n",
      "Done Scraping Psychology\n",
      "Done Scraping Autobiography\n",
      "Done Scraping Parenting\n",
      "Done Scraping Adult Fiction\n",
      "Done Scraping Humor\n",
      "Done Scraping Horror\n",
      "Done Scraping History\n",
      "Done Scraping Food and Drink From 2 Pages\n",
      "Done Scraping Christian Fiction\n",
      "Done Scraping Business\n",
      "Done Scraping Biography\n",
      "Done Scraping Thriller\n",
      "Done Scraping Contemporary\n",
      "Done Scraping Spirituality\n",
      "Done Scraping Academic\n",
      "Done Scraping Self Help\n",
      "Done Scraping Historical\n",
      "Done Scraping Christian\n",
      "Done Scraping Suspense\n",
      "Done Scraping Short Stories\n",
      "Done Scraping Novels\n",
      "Done Scraping Health\n",
      "Done Scraping Politics\n",
      "Done Scraping Cultural\n",
      "Done Scraping Erotica\n",
      "Done Scraping Crime\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Category</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>Two</td>\n",
       "      <td>Travel</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Moon over Noah’s Ark: An Odyssey to Mount...</td>\n",
       "      <td>£49.43</td>\n",
       "      <td>Four</td>\n",
       "      <td>Travel</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>See America: A Celebration of Our National Par...</td>\n",
       "      <td>£48.87</td>\n",
       "      <td>Three</td>\n",
       "      <td>Travel</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vagabonding: An Uncommon Guide to the Art of L...</td>\n",
       "      <td>£36.94</td>\n",
       "      <td>Two</td>\n",
       "      <td>Travel</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Under the Tuscan Sun</td>\n",
       "      <td>£37.33</td>\n",
       "      <td>Three</td>\n",
       "      <td>Travel</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Why the Right Went Wrong: Conservatism--From G...</td>\n",
       "      <td>£52.65</td>\n",
       "      <td>Four</td>\n",
       "      <td>Politics</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Equal Is Unfair: America's Misguided Fight Aga...</td>\n",
       "      <td>£56.86</td>\n",
       "      <td>One</td>\n",
       "      <td>Politics</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Amid the Chaos</td>\n",
       "      <td>£36.58</td>\n",
       "      <td>One</td>\n",
       "      <td>Cultural</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Dark Notes</td>\n",
       "      <td>£19.19</td>\n",
       "      <td>Five</td>\n",
       "      <td>Erotica</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The Long Shadow of Small Ghosts: Murder and Me...</td>\n",
       "      <td>£10.97</td>\n",
       "      <td>One</td>\n",
       "      <td>Crime</td>\n",
       "      <td>https://books.toscrape.com/catalogue/../../../...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name   Price Rating  \\\n",
       "0                              It's Only the Himalayas  £45.17    Two   \n",
       "1    Full Moon over Noah’s Ark: An Odyssey to Mount...  £49.43   Four   \n",
       "2    See America: A Celebration of Our National Par...  £48.87  Three   \n",
       "3    Vagabonding: An Uncommon Guide to the Art of L...  £36.94    Two   \n",
       "4                                 Under the Tuscan Sun  £37.33  Three   \n",
       "..                                                 ...     ...    ...   \n",
       "995  Why the Right Went Wrong: Conservatism--From G...  £52.65   Four   \n",
       "996  Equal Is Unfair: America's Misguided Fight Aga...  £56.86    One   \n",
       "997                                     Amid the Chaos  £36.58    One   \n",
       "998                                         Dark Notes  £19.19   Five   \n",
       "999  The Long Shadow of Small Ghosts: Murder and Me...  £10.97    One   \n",
       "\n",
       "     Category                                               Link  \n",
       "0      Travel  https://books.toscrape.com/catalogue/../../../...  \n",
       "1      Travel  https://books.toscrape.com/catalogue/../../../...  \n",
       "2      Travel  https://books.toscrape.com/catalogue/../../../...  \n",
       "3      Travel  https://books.toscrape.com/catalogue/../../../...  \n",
       "4      Travel  https://books.toscrape.com/catalogue/../../../...  \n",
       "..        ...                                                ...  \n",
       "995  Politics  https://books.toscrape.com/catalogue/../../../...  \n",
       "996  Politics  https://books.toscrape.com/catalogue/../../../...  \n",
       "997  Cultural  https://books.toscrape.com/catalogue/../../../...  \n",
       "998   Erotica  https://books.toscrape.com/catalogue/../../../...  \n",
       "999     Crime  https://books.toscrape.com/catalogue/../../../...  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store the scraped data and pagination start\n",
    "title = []\n",
    "price = []\n",
    "star = []\n",
    "category = []\n",
    "link = []\n",
    "\n",
    "# Loop through each category and scrape the book details\n",
    "for category_url in category_links:\n",
    "    if 'page' in category_url:\n",
    "        page_num = 1\n",
    "        while True:\n",
    "            category_url = category_url[:-6] + f'{page_num}' + category_url[-5:]\n",
    "            result = requests.get(category_url)\n",
    "            src = result.content\n",
    "            soup = BeautifulSoup(src, \"lxml\")\n",
    "            total_pages = int(soup.find('li', {'class':'current'}).text.split('of')[1].strip())\n",
    "            \n",
    "            categorys = soup.find('h1').text.strip()\n",
    "            titles = soup.find_all('h3')\n",
    "            prices = soup.find_all('p', {'class':'price_color'})\n",
    "            stars = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "            links = soup.find_all('h3')\n",
    "\n",
    "            for i in range(len(titles)):\n",
    "                title.append(titles[i].find('a').get('title'))\n",
    "                price.append(prices[i].text)\n",
    "                star.append(stars[i].select_one(\"p.star-rating\").get(\"class\")[1])\n",
    "                category.append(categorys)\n",
    "                link.append('https://books.toscrape.com/catalogue/' + links[i].find('a').get('href'))\n",
    "            \n",
    "            page_num += 1\n",
    "            \n",
    "            \n",
    "            if (page_num > total_pages):\n",
    "                print(f'Done Scraping {categorys} From {page_num-1} Pages')\n",
    "                break\n",
    "    else:\n",
    "        result = requests.get(category_url)\n",
    "        src = result.content\n",
    "        soup = BeautifulSoup(src, \"lxml\")\n",
    "        categorys = soup.find('h1').text.strip()\n",
    "        titles = soup.find_all('h3')\n",
    "        prices = soup.find_all('p', {'class':'price_color'})\n",
    "        stars = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "        links = soup.find_all('h3')\n",
    "\n",
    "        for i in range(len(titles)):\n",
    "            title.append(titles[i].find('a').get('title'))\n",
    "            price.append(prices[i].text)\n",
    "            star.append(stars[i].select_one(\"p.star-rating\").get(\"class\")[1])\n",
    "            category.append(categorys)\n",
    "            link.append('https://books.toscrape.com/catalogue/' + links[i].find('a').get('href'))\n",
    "        print(f'Done Scraping {categorys}')\n",
    "\n",
    "with open('Books.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Name', 'Price', 'Rating', 'Category', 'Link'])\n",
    "        for i in range(len(title)):\n",
    "            writer.writerow([title[i], price[i], star[i], category[i], link[i]])\n",
    "pd.read_csv('Books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Done By</summary>\n",
    "<center> Ahmed NasrElDin </center> \n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f35561962b3536e798d9d7f8aed8a6570157df2537699a33c475af9309799d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
